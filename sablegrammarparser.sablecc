Package SableGrammarParser;

Helpers
    all = [0 .. 0xFFFF];  
    lowercase = ['a' .. 'z'];
    uppercase = ['A' .. 'Z'];
    digit = ['0' .. '9'];
    hex_digit = [digit + [['a' .. 'f'] + ['A' .. 'F']]];

    tab = 9;
    cr = 13;
    lf = 10;
    eol = cr lf | cr | lf;        // This takes care of different platforms

    not_cr_lf = [all - [cr + lf]];
    not_star = [all - '*'];
    not_star_slash = [not_star - '/'];

    blank = (' ' | tab | eol)+;

    short_comment = '//' not_cr_lf* eol;
    long_comment = '/*' not_star* '*'+ (not_star_slash not_star* '*'+)* '/';
    comment = short_comment | long_comment;

    letter = lowercase | uppercase | '_' | '$'; 
    id_part = lowercase (lowercase | digit)*;

States
    normal,
    package;

Tokens
{package}
    packagename = letter (letter | digit)* ('.' letter (letter | digit)*)*;

{normal->package}
    packagetoken = 'Package';
    statestoken = 'States';
    helperstoken = 'Helpers';
    tokenstoken = 'Tokens';
    ignoredtoken = 'Ignored';
    productionstoken = 'Productions';

    token_specifier = 'T';
    production_specifier = 'P';

    dot = '.';
    d_dot = '..';

{normal, package->normal}
    semicolon = ';';

    equal = '=';
    l_bkt = '[';
    r_bkt = ']';
    l_par = '(';
    r_par = ')';
    l_brace =  '{';
    r_brace =  '}';
    plus = '+';
    minus = '-';
    q_mark = '?';
    star = '*';
    pipe = '|';
    comma = ',';
    slash = '/';
    arrow = '->';
    colon = ':';

    identifier = id_part ('_' id_part)*;

    character = ''' not_cr_lf ''';
    dec_char = digit+;
    hex_char = '0' ('x' | 'X') hex_digit+;

    string = ''' [not_cr_lf - ''']+ ''';

    blank = blank;
    comment = comment;

Ignored Tokens
    blank,
    comment;

Productions
    grammar
		= package? helpers? states? tokens? ign_tokens? productions?
		{-> New grammar(package.package, helpers.helpers, states.states, tokens.tokens, ign_tokens.ignoredtokens)}
		;

    package = 
        packagetoken packagename semicolon;

    helpers
		= helperstoken [helper_defs]:helper_def+ {-> New helpers(helperstoken, [helper_defs.helper])}
		;

    helper_def {-> helper}
		= identifier equal reg_exp semicolon {-> New helper(identifier, equal, reg_exp.regex, semicolon)}
		;

    states
		= statestoken id_list semicolon {-> New states(statestoken, New list.identifier([id_list.listitem]), semicolon)}
		;

    id_list {-> listitem+}
		= identifier [ids]:id_list_tail* {-> [New listitem.identifier(Null, identifier), ids.listitem]}
		;

    id_list_tail {-> listitem}
		= comma identifier {-> New listitem.identifier(comma, identifier)}
		;

    tokens
		= tokenstoken [token_defs]:token_def+ {-> New tokens(tokenstoken, [token_defs.token])}
		;

    token_def {-> token}
		= state_list? identifier equal reg_exp look_ahead? semicolon {-> New token(state_list.list, identifier, equal, reg_exp.regex, look_ahead.tokenlookahead, semicolon)}
		;

    state_list {-> list}
		= {notransition} l_brace identifier [state_lists]:state_list_tail* r_brace
		  {-> New list.tokenstate(l_brace, [New listitem.tokenstate(Null, identifier), state_lists.listitem], r_brace)}
		| {transition} l_brace [f]:identifier arrow [t]:identifier [state_lists]:state_list_tail* r_brace
		  {-> New list.tokenstate(l_brace, [New listitem.tokenstatetransition(Null, f, arrow, t), state_lists.listitem], r_brace)}
		;

    state_list_tail {-> listitem}
		= {notransition} comma identifier {-> New listitem.tokenstate(comma, identifier)}
		| {transition} comma [f]:identifier arrow [t]:identifier {-> New listitem.tokenstatetransition(comma, f, arrow, t)}
		;

    ign_tokens {-> ignoredtokens}
		= ignoredtoken tokenstoken id_list semicolon {-> New ignoredtokens(ignoredtoken, tokenstoken, New list.identifier([id_list.listitem]), semicolon)}
		;

    look_ahead {-> tokenlookahead}
		= slash reg_exp {-> New tokenlookahead(slash, reg_exp.regex)}
		;

    reg_exp {-> regex}
		= {single} concat {-> New regex.sequence([concat.regexpart])}
		| {multiple} concat [concats]:reg_exp_tail+ {-> New regex.or([New orpart.regex(Null, [concat.regexpart]), concats.orpart])}
		;

    reg_exp_tail {-> orpart}
		= pipe concat {-> New orpart.regex(pipe, [concat.regexpart])}
		;

    concat {-> regexpart+}
		= [un_exps]:un_exp+ {-> [un_exps.regexpart]}
		;

    un_exp {-> regexpart}
		= {simple} basic {-> basic.regexpart}
		| {star} basic star {-> New regexpart.unarystar(basic.regexpart, star)}
		| {question} basic q_mark {-> New regexpart.unaryquestion(basic.regexpart, q_mark)}
		| {plus} basic plus {-> New regexpart.unaryplus(basic.regexpart, plus)}
		;

    basic {-> regexpart}
		= {char} char {-> char.regexpart}
		| {set} set {-> set.regexpart}
		| {string} string {-> New regexpart.string(string)}
		| {identifier} identifier {-> New regexpart.identifier(identifier)}
		| {reg_exp} l_par reg_exp r_par {-> New regexpart.parenthesis(l_par, reg_exp.regex, r_par)}
		;

    char {-> regexpart}
		= {char} character {-> New regexpart.char(character)}
		| {dec}  dec_char {-> New regexpart.dec(dec_char)}
		| {hex}  hex_char {-> New regexpart.hex(hex_char)}
		;

    set {-> regexpart}
		= {plus} l_bkt [left]:basic plus [right]:basic r_bkt {-> New regexpart.binaryplus(l_bkt, left.regexpart, plus, right.regexpart, r_bkt)}
        | {minus} l_bkt [left]:basic minus [right]:basic r_bkt {-> New regexpart.binaryminus(l_bkt, left.regexpart, minus, right.regexpart, r_bkt)}
		| {interval} l_bkt [left]:char d_dot [right]:char r_bkt {-> New regexpart.interval(l_bkt, left.regexpart, d_dot, right.regexpart, r_bkt)}
		;

    un_op = 
        {star}   star |
        {q_mark} q_mark |
        {plus}   plus;

    productions =
        productionstoken [prods]:prod+;

    prod =
        identifier equal alts semicolon;

    alts =
        alt [alts]:alts_tail*;

    alts_tail =
        pipe alt;

    alt =
        {parsed} alt_name? [elems]:elem* |
        {ignored} l_par alt_name? [elems]:elem* r_par;
        
    alt_name =
        l_brace identifier r_brace;

    elem =
        elem_name? specifier? identifier un_op?;

    elem_name =
        l_bkt identifier r_bkt colon;

    specifier =
        {token}         token_specifier dot |
        {production} production_specifier dot;

Abstract Syntax Tree
	grammar = package? helpers? states? tokens? ignoredtokens?;
	package = packagetoken packagename semicolon;
	
	helpers = helperstoken [helpers]:helper*;
	helper = identifier equal regex semicolon;
	
	tokens = tokenstoken [tokens]:token*;
	token = list? identifier equal regex tokenlookahead? semicolon;
	tokenlookahead = slash regex;
	
	regex
		= {sequence} regexpart+
		| {or} orpart+
		;
	orpart = {regex} pipe? regexpart+;
	regexpart
		= {char} character
		| {dec} dec_char
		| {hex} hex_char
		
		| {unarystar} regexpart star
		| {unaryquestion} regexpart [question]:q_mark
		| {unaryplus} regexpart plus
		
		| {binaryplus} [lpar]:l_bkt [left]:regexpart plus [right]:regexpart [rpar]:r_bkt
		| {binaryminus} [lpar]:l_bkt [left]:regexpart minus [right]:regexpart [rpar]:r_bkt
		| {interval} [lpar]:l_bkt [left]:regexpart [dots]:d_dot [right]:regexpart [rpar]:r_bkt
		
		| {string} string
		| {identifier} identifier
		| {parenthesis} [lpar]:l_par regex [rpar]:r_par
		;
	
	states = statestoken list semicolon;
	ignoredtokens = ignoredtoken tokenstoken list semicolon;
	list
		= {identifier} listitem+
		| {tokenstate} [lpar]:l_brace listitem+ [rpar]:r_brace
		;
	listitem
		= {identifier} comma? identifier
		| {tokenstate} comma? identifier
		| {tokenstatetransition} comma? [from]:identifier arrow [to]:identifier
		;
